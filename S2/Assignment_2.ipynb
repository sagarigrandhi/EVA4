{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Assignment_2.ipynb","provenance":[{"file_id":"1uJZvJdi5VprOQHROtJIHy0mnY2afjNlx","timestamp":1589119635988}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"dc92306a00cb4ef0ade85b59bebb3fa6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_13713a11d26b45fcaa7581b646fbff22","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_45281268bfef427fabf3e062e2540174","IPY_MODEL_0a9969a900eb412398802aa88ec8076e"]}},"13713a11d26b45fcaa7581b646fbff22":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"45281268bfef427fabf3e062e2540174":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_14f60a303d8b47b9ab2bf554a786266c","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3bc7c7891e7a4c40ab6afa769a859481"}},"0a9969a900eb412398802aa88ec8076e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0e284ef8c0e247069b92e99bef64d997","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 9920512/? [00:19&lt;00:00, 1930984.21it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_721663d3c4094327b2737f2f2352aadb"}},"14f60a303d8b47b9ab2bf554a786266c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"3bc7c7891e7a4c40ab6afa769a859481":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0e284ef8c0e247069b92e99bef64d997":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"721663d3c4094327b2737f2f2352aadb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"51d192f682454dee9f85d3c609e74a7b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4f2dc0dc341f4826be8ddcabf66992a6","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f99d7c32c8ad40d9a9db8f9c2fd99c09","IPY_MODEL_0c29d9c58a3c42c0a5a4f1b2335c8613"]}},"4f2dc0dc341f4826be8ddcabf66992a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f99d7c32c8ad40d9a9db8f9c2fd99c09":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_87dd463ba47d489fa721522088af0277","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_31139da4ab9149549ccfaf0ed1a289cd"}},"0c29d9c58a3c42c0a5a4f1b2335c8613":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_efbc34bc5989457887bb18072f075db3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 32768/? [00:00&lt;00:00, 62215.27it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_dfbb070a8c1c4b059579cca6c39792be"}},"87dd463ba47d489fa721522088af0277":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"31139da4ab9149549ccfaf0ed1a289cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"efbc34bc5989457887bb18072f075db3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"dfbb070a8c1c4b059579cca6c39792be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"66f7574da9d74dee8bb54c93aecb0cfd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d58e8e9741de4631b36db89cad0fbebf","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f65cb6e756d04ec98ce783a7ec6e008d","IPY_MODEL_a77b097adcff4ed7939ecddc99ceefae"]}},"d58e8e9741de4631b36db89cad0fbebf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f65cb6e756d04ec98ce783a7ec6e008d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_89e11c2984224beb927d8417c5a7c98e","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2ac08329e6e342618bf10d93b66585f0"}},"a77b097adcff4ed7939ecddc99ceefae":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4d8b64446570418197b969aae624141f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1654784/? [00:00&lt;00:00, 4239476.33it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b60796d2979a44369a22d600bed6d6a4"}},"89e11c2984224beb927d8417c5a7c98e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2ac08329e6e342618bf10d93b66585f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4d8b64446570418197b969aae624141f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b60796d2979a44369a22d600bed6d6a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1d73428a269343a0b86e1095cbf9fa37":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_67a0190185a64718aa6b3fda9751a1bd","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_0025998914d24a39918695d06f682f94","IPY_MODEL_9358eca8a11d4fc3900220c5336049ab"]}},"67a0190185a64718aa6b3fda9751a1bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0025998914d24a39918695d06f682f94":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3ebdc963b114471c869ce437836b25d6","_dom_classes":[],"description":"  0%","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":0,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8bbefbe1299244c29545cb8127d7068c"}},"9358eca8a11d4fc3900220c5336049ab":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_96cabbe6a5d14380b48b461b911f301b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0/4542 [00:00&lt;?, ?it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8e7dacd62e204381bd18c90dd46b395b"}},"3ebdc963b114471c869ce437836b25d6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"8bbefbe1299244c29545cb8127d7068c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"96cabbe6a5d14380b48b461b911f301b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8e7dacd62e204381bd18c90dd46b395b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"91yZp_S-PMt5","colab_type":"text"},"source":["## Session 2 Assignment:\n","1. read the file carefully \n","2. add comments to all the cells carefully, explaining exactly what that cell does (for your own good)! \n","3. in the cell where the main model is defined:\n"," 1. write receptive field of each layer as a comment\n"," 2. write the input channel dimensions\n","4. run each cell one by one\n","5. experiment\n","6. Once you are done with your experiments, attempt S2 Solution Quiz. You will have 45 minutes to answer questions about this code. You will also be running the code once/twice within this 45 minutes. \n","7. Read the S2 - Solution Quiz carefully before attempting it. "]},{"cell_type":"markdown","metadata":{"id":"rlLnuGjzVK4a","colab_type":"text"},"source":["## Import libraries"]},{"cell_type":"code","metadata":{"id":"0m2JWFliFfKT","colab_type":"code","colab":{}},"source":["from __future__ import print_function\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DsZF8gk2VfIZ","colab_type":"text"},"source":["## Model definition"]},{"cell_type":"code","metadata":{"id":"h_Cx9q2QFgM7","colab_type":"code","colab":{}},"source":["class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 32, 3, padding=1) # input - 28*28*1, output - 28*28*32, RF - 3*3\n","        self.conv2 = nn.Conv2d(32, 64, 3, padding=1) # input - 28*28*32, output - 28*28*64, RF - 5*5\n","        self.pool1 = nn.MaxPool2d(2, 2) # input - 28*28*64, output - 14*14*64, RF - 10*10\n","        self.conv3 = nn.Conv2d(64, 128, 3, padding=1) # input - 14*14*64, output - 14*14*128, RF - 12*12\n","        self.conv4 = nn.Conv2d(128, 256, 3, padding=1) # input - 14*14*128, output - 14*14*256, RF - 14*14\n","        self.pool2 = nn.MaxPool2d(2, 2) # input - 14*14*256, output - 7*7*256, RF - 28*28\n","        self.conv5 = nn.Conv2d(256, 512, 3) # input - 7*7*256, output - 5*5*512, RF - 30*30\n","        self.conv6 = nn.Conv2d(512, 1024, 3) # input - 5*5*512, output - 3*3*1024, RF - 32*32\n","        self.conv7 = nn.Conv2d(1024, 10, 3) # input - 3*3*1024, output - 1*1*10, RF - 34*34\n","\n","    def forward(self, x):\n","        x = self.pool1(F.relu(self.conv2(F.relu(self.conv1(x)))))\n","        x = self.pool2(F.relu(self.conv4(F.relu(self.conv3(x)))))\n","        x = F.relu(self.conv6(F.relu(self.conv5(x))))\n","        x = self.conv7(x) # Removed last RELU to get 95+ accuracy in first epoch\n","        x = x.view(-1, 10)\n","        return F.log_softmax(x)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vLkAVYTUVjay","colab_type":"text"},"source":["## Model summary "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"xdydjYTZFyi3","colab":{"base_uri":"https://localhost:8080/","height":459},"executionInfo":{"status":"ok","timestamp":1594458129525,"user_tz":-330,"elapsed":18641,"user":{"displayName":"RATNA SAGARI GRANDHI","photoUrl":"","userId":"00321448433151079710"}},"outputId":"27687ab1-eafc-4bdb-a9bd-d6d8829c2ca9"},"source":["!pip install torchsummary\n","from torchsummary import summary\n","use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","model = Net().to(device)\n","summary(model, input_size=(1, 28, 28))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torchsummary in /usr/local/lib/python3.6/dist-packages (1.5.1)\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 32, 28, 28]             320\n","            Conv2d-2           [-1, 64, 28, 28]          18,496\n","         MaxPool2d-3           [-1, 64, 14, 14]               0\n","            Conv2d-4          [-1, 128, 14, 14]          73,856\n","            Conv2d-5          [-1, 256, 14, 14]         295,168\n","         MaxPool2d-6            [-1, 256, 7, 7]               0\n","            Conv2d-7            [-1, 512, 5, 5]       1,180,160\n","            Conv2d-8           [-1, 1024, 3, 3]       4,719,616\n","            Conv2d-9             [-1, 10, 1, 1]          92,170\n","================================================================\n","Total params: 6,379,786\n","Trainable params: 6,379,786\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 1.51\n","Params size (MB): 24.34\n","Estimated Total Size (MB): 25.85\n","----------------------------------------------------------------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"kGBrsnMOVY-C","colab_type":"text"},"source":["## Prepare and load the dataset"]},{"cell_type":"code","metadata":{"id":"DqTWLaM5GHgH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":393,"referenced_widgets":["dc92306a00cb4ef0ade85b59bebb3fa6","13713a11d26b45fcaa7581b646fbff22","45281268bfef427fabf3e062e2540174","0a9969a900eb412398802aa88ec8076e","14f60a303d8b47b9ab2bf554a786266c","3bc7c7891e7a4c40ab6afa769a859481","0e284ef8c0e247069b92e99bef64d997","721663d3c4094327b2737f2f2352aadb","51d192f682454dee9f85d3c609e74a7b","4f2dc0dc341f4826be8ddcabf66992a6","f99d7c32c8ad40d9a9db8f9c2fd99c09","0c29d9c58a3c42c0a5a4f1b2335c8613","87dd463ba47d489fa721522088af0277","31139da4ab9149549ccfaf0ed1a289cd","efbc34bc5989457887bb18072f075db3","dfbb070a8c1c4b059579cca6c39792be","66f7574da9d74dee8bb54c93aecb0cfd","d58e8e9741de4631b36db89cad0fbebf","f65cb6e756d04ec98ce783a7ec6e008d","a77b097adcff4ed7939ecddc99ceefae","89e11c2984224beb927d8417c5a7c98e","2ac08329e6e342618bf10d93b66585f0","4d8b64446570418197b969aae624141f","b60796d2979a44369a22d600bed6d6a4","1d73428a269343a0b86e1095cbf9fa37","67a0190185a64718aa6b3fda9751a1bd","0025998914d24a39918695d06f682f94","9358eca8a11d4fc3900220c5336049ab","3ebdc963b114471c869ce437836b25d6","8bbefbe1299244c29545cb8127d7068c","96cabbe6a5d14380b48b461b911f301b","8e7dacd62e204381bd18c90dd46b395b"]},"executionInfo":{"status":"ok","timestamp":1594458130858,"user_tz":-330,"elapsed":19961,"user":{"displayName":"RATNA SAGARI GRANDHI","photoUrl":"","userId":"00321448433151079710"}},"outputId":"b816a819-d9c0-4b36-e694-96e306846eef"},"source":["torch.manual_seed(1)\n","batch_size = 128\n","\n","kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n","train_loader = torch.utils.data.DataLoader(\n","    datasets.MNIST('../data', train=True, download=True,\n","                    transform=transforms.Compose([\n","                        transforms.ToTensor(),\n","                        transforms.Normalize((0.1307,), (0.3081,))\n","                    ])),\n","    batch_size=batch_size, shuffle=True, **kwargs)\n","test_loader = torch.utils.data.DataLoader(\n","    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n","                        transforms.ToTensor(),\n","                        transforms.Normalize((0.1307,), (0.3081,))\n","                    ])),\n","    batch_size=batch_size, shuffle=True, **kwargs)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dc92306a00cb4ef0ade85b59bebb3fa6","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"51d192f682454dee9f85d3c609e74a7b","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"66f7574da9d74dee8bb54c93aecb0cfd","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n","\n","\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1d73428a269343a0b86e1095cbf9fa37","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n","Processing...\n","Done!\n"],"name":"stdout"},{"output_type":"stream","text":["/pytorch/torch/csrc/utils/tensor_numpy.cpp:141: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"0jAJoUOlVwxe","colab_type":"text"},"source":["## Model training and validation"]},{"cell_type":"code","metadata":{"id":"8fDefDhaFlwH","colab_type":"code","colab":{}},"source":["from tqdm import tqdm\n","def train(model, device, train_loader, optimizer, epoch):\n","    model.train()\n","    pbar = tqdm(train_loader)\n","    for batch_idx, (data, target) in enumerate(pbar):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = F.nll_loss(output, target)\n","        loss.backward()\n","        optimizer.step()\n","        pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx}')\n","\n","\n","def test(model, device, test_loader):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n","            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","    test_loss /= len(test_loader.dataset)\n","\n","    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n","        test_loss, correct, len(test_loader.dataset),\n","        100. * correct / len(test_loader.dataset)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H7oy0acmV7Sk","colab_type":"text"},"source":["## Optimizer definition and running the model"]},{"cell_type":"code","metadata":{"id":"MMWbLWO6FuHb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":125},"executionInfo":{"status":"ok","timestamp":1594458173309,"user_tz":-330,"elapsed":62365,"user":{"displayName":"RATNA SAGARI GRANDHI","photoUrl":"","userId":"00321448433151079710"}},"outputId":"b74f9355-840d-4afc-e470-7d0d23cdf50e"},"source":["model = Net().to(device)\n","optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n","\n","for epoch in range(1, 2):\n","    train(model, device, train_loader, optimizer, epoch)\n","    test(model, device, test_loader)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n","loss=0.03553972393274307 batch_id=468: 100%|██████████| 469/469 [00:38<00:00, 12.06it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0655, Accuracy: 9796/10000 (98%)\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MCxR9ySjbsnH","colab_type":"text"},"source":["## S2 - Solution Quiz:\n","1. What is torch?\n","\n"," An open source machine learning framework that accelerates the path from research prototyping to production deployment.\n","\n","2. What is the purpose of adding padding = 1?\n"," \n"," To add 2 additional pixels in x and y rows for convolution.\n","\n","3. What is that -1 in output shape when we call summary(model,input_size = (1,28,28))?\n"," \n"," * It refers to batch size.\n"," * It refers to the dimension \"outside\" what might be available of input_size.\n","\n","4. What is CUDA?\n"," \n"," CUDA is a parallel computing platform and application programming interface model created by Nvidia. It allows software developers and software engineers to use a CUDA-enabled graphics processing unit for general purpose processing - an approach termed GPGPU.\n","\n","5. What is a Tensor?\n"," \n"," * A tensor is a container which can house data in N dimensions.\n"," * A tensor is NOT a matrix, as matrices are specifically 2D, where as Tensors can be nD.\n"," * is an algebraic object that describes a linear mapping from one set of algebraic objects to another.\n","\n","6. What is 0.1307 and 0.3081 in transforms.Normalize?\n","\n"," That's the mean and std of the training dataset (not complete dataset).\n","\n","7. What is the use of torch.no_grad()?\n","   \n","   * To perform inference, but without training.\n","   * To make sure test data does not \"leak\" into the model.\n","   * To perform inference without gradient calculation.\n","\n","8. What is wrong with this model? Generally in 1 epoch we should be able to get 95%+, but here we do not? \n"," \n"," Not attempted.\n"," (Answer: last ReLU layer)\n","\n","9. Only 1 change is required in this model such that it gets up to 97% within 1 epoch! What is that 1 change? \n"," \n"," Not attempted.\n"," (Answer: remove ReLU layer)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"yd7_JBiE8Sqs","colab_type":"text"},"source":["## Quiz 2:\n","1. If we perform convolution with a kernel of size 3x3 on 47x49, the output size would be?\n"," \n"," 45x47\n","\n","2. Which of these are true, w.r.t. what we discussed in Session 2?\n","\n","   * We always use a kernel with size 3x3.\n","   * We always use kernels with stride of 1.\n","   * We add as many layers as required to reach full image/object size.\n","\n","3. How many 3x3 layers do we need to add to reach a receptive field of 21x21?\n","\n"," 10\n","\n","4. Let us assume we have an image of size 100x100. What is the minimum number of convolution layers do we need to add such that \n","\n"," 1. you cannot use max-pooling without convolving twice or more\n"," 2. the output is at least 2-3 convolution layers away from max-pooling\n"," 3. You can stop either at 2x2 or 1x1 based on how you have used your layers\n"," 4. we will always \"not consider\" the last rows and columns in an odd-resolution channel while performing max-pooling)\n"," 5. \"do not\" count max-pooling layer\n"," \n"," 10\n","\n"," 100x100 | 3x3 (conv)\n","98x98 | 3x3 (conv)\n","96x96 | 3x3 (conv)\n","48x48 | 3x3 (conv)\n","46x46 | 3x3 (conv)\n","44x44 | 2x2 (maxpool)\n","22x22 | 3x3 (conv)\n","20x20 | 3x3 (conv)\n","18x18 | 3x3 (maxpool)\n","9x9 | 3x3 (conv)\n","7x7 | 3x3 (conv)\n","5x5 | 3x3 (conv)\n","3x3 | 3x3 (conv)\n","1x1\n","\n","5. If the input channels have 128 layers, how many kernels do we need to add?\n"," Number of kernels do not depend on input channels.\n","\n","6. Consider the following layers\n"," \n"," ...\n","49x49x256 | Convolved with 512 kernels of size 3x3 |\n","... What is the total number of kernel parameters we just added?\n"," \n"," 1179648\n","\n","7. Consider this network\n","\n"," 400x400x3 | 32x(3x3x3) |\n","398x398x32 | 64x(3x3x32) |\n","396x396x64 | 128x(3x3x64) |\n","394x394x128 | 256x(3x3x128) |\n","392x392x256 | 512x(3x3x256) |\n","390x390x512 | 1024x(3x3x256) |\n","MaxPooling(2x2)...\n","\n"," Assume this network is trained and we are doing inference on an image. Before we hit the max-pooling layer, how many channels of size more than 350x350 are there in the GPU RAM?\n","\n"," 2019\n","\n","8. What are few advantage of using MaxPooling?\n"," \n"," * Reduction in Channel Size\n"," * Slight Rotational Invariance\n"," * Slight Translational Invariance\n","\n","9. If we start with an image of 400x400 color, and during a model we use MaxPooling 4 times, reducing the image size to 400>200>100>50 (we used convs with padding, so convs did not reduce the image size), have we lost 4 times the information we started with? At 50x50 we have 1000 channels.\n"," \n"," No, convs and poolings operation are loosing some information, but more importantly, they are \"filtering\" the information. We do not need full information at the last layer, just the most important one. We are also scaling in Z axis (from 3 to 1000), and it is the increase in z axis where we store this \"proposed\" lost information.\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"w0kbM7aPgVah","colab_type":"text"},"source":["### That's all Folks!"]}]}